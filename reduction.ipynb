{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this notebook to reduce data from the Nickel Telescope. Be sure to read the notes in between the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from astropy.io import fits\n",
    "\n",
    "from overscan_subtraction import overscan_subtraction\n",
    "from bias_subtraction import bias_subtraction\n",
    "from dark_subtraction import dark_subtraction\n",
    "from flat_division import flat_division\n",
    "from correct_object_name import correct_object_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reduction requires the OBJECT names in the raw FITS files (which are set at the time of the observation) to be one of the following:\n",
    "- \"bias\"\n",
    "- \"dark\"\n",
    "- \"dome flat\"\n",
    "- \"sky flat\" (i.e., flats taken of the sky at sunset)\n",
    "- \"focus\"\n",
    "- your target names (can be anything)\n",
    "\n",
    "If you need to correct OBJECT an in FITS headers of any files, do that below. If everything is correct, ignore the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_object(myfiles, \"dark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're ready to reduce your data. First, get a list of all the raw data files. The name of the directory with the raw data should have format 'YYYY-MM-DD-nickel-raw'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdir = \"\" # path to directory with raw data\n",
    "rawfiles = [rawdir + file for file in sorted(os.listdir(rawdir))]\n",
    "# rawfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create processing and reduced directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdir_split = rawdir.split(\"/\")\n",
    "if rawdir_split[-1] == \"\":\n",
    "    rootdir = \"/\".join(rawdir_split[:-2])+\"/\"\n",
    "    datadir = rawdir_split[-2]+\"/\"\n",
    "else:\n",
    "    rootdir = \"/\".join(rawdir_split[:-1])+\"/\"\n",
    "    datadir = rawdir_split[-1]+\"/\"\n",
    "    \n",
    "datadir_split = datadir.split(\"-\")\n",
    "\n",
    "procdir = \"-\".join(datadir_split[:4])+\"-proc/\"\n",
    "os.makedirs(rootdir+procdir)\n",
    "reddir = \"-\".join(datadir_split[:4])+\"-red/\"\n",
    "os.makedirs(rootdir+reddir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do overscan subtraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procdir = rootdir+procdir\n",
    "procfiles = [procdir + file.split('.')[0] + '_proc.' + file.split('.')[1] for file in sorted(os.listdir(rawdir))]\n",
    "overscan_subtraction(rawfiles, procfiles, 'yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a dataframe of all the files we want to continue reducing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_list = []\n",
    "exptime_list = []\n",
    "filt_list = []\n",
    "\n",
    "for procfile in procfiles:\n",
    "    hdul = fits.open(procfile)\n",
    "    obj_list.append(hdul[0].header[\"OBJECT\"])\n",
    "    exptime_list.append(hdul[0].header[\"EXPTIME\"])\n",
    "    filt_list.append(hdul[0].header[\"FILTNAM\"])\n",
    "    hdul.close()\n",
    "    \n",
    "df_log = pd.DataFrame({\n",
    "    \"file\": procfiles,\n",
    "    \"object\": obj_list,\n",
    "    \"exptime\": exptime_list,\n",
    "    \"filt\": filt_list\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do bias subtraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather all the bias frames\n",
    "biasfiles = list(df_log.file[df_log.object == 'bias'])\n",
    "\n",
    "# average all of them into one\n",
    "biasdata = []\n",
    "for biasfile in biasfiles:\n",
    "    hdul = fits.open(biasfile)\n",
    "    biasdata.append(hdul[0].data)\n",
    "    hdul.close()\n",
    "bias = np.stack(biasdata).mean(axis=0)\n",
    "# omit hot column so that it is properly flat-fielded out\n",
    "bias[:,256] = 0\n",
    "\n",
    "# gather all non-bias files\n",
    "nonbiasfiles = list(df_log.file[df_log.object != 'bias'])\n",
    "\n",
    "bias_subtraction(nonbiasfiles, nonbiasfiles, bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do dark subtraction.\n",
    "\n",
    "This can usually be skipped, since the Nickel CCD has a very low dark current, but it is included here for the sake of completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'dark' in list(set(obj_list)):\n",
    "#     darkexptimes = list(set(df_log.exptime[df_log.object == 'dark']))\n",
    "#     for darkexptime in darkexptimes:\n",
    "#         # find all files with this exposure time\n",
    "#         darkfiles = list(df_log.file[(df_log.object == 'dark') & (df_log.exptime == darkexptime)])\n",
    "#         flatfiles = list(df_log.file[((df_log.object == 'dome flat') | (df_log.object == 'sky flat')) &\n",
    "#                                      (df_log.exptime == darkexptime)])\n",
    "#         sciencefiles = list(df_log.file[(df_log.object != 'bias') &\n",
    "#                                         (df_log.object != 'dark') &\n",
    "#                                         (df_log.object != 'dome flat') &\n",
    "#                                         (df_log.object != 'sky flat') &\n",
    "#                                         (df_log.object != 'focus') &\n",
    "#                                         (df_log.exptime == darkexptime)])\n",
    "        \n",
    "#         # calculate average dark frame\n",
    "#         if len(darkfiles) > 1:\n",
    "#             darkdata = []\n",
    "#             for darkfile in darkfiles:\n",
    "#                 hdul = fits.open(darkfile)\n",
    "#                 darkdata.append(hdul[0].data)\n",
    "#                 hdul.close()\n",
    "#             dark = np.stack(darkdata).mean(axis=0)\n",
    "#         else:\n",
    "#             hdul = fits.open(darkfile)\n",
    "#             dark = hdul[0].data\n",
    "#             hdul.close()\n",
    "        \n",
    "#         # do dark subtraction\n",
    "#         if len(flatfiles) > 0:\n",
    "#             dark_subtraction(flatfiles, flatfiles, dark)\n",
    "#         if len(sciencefiles) > 0:\n",
    "#             dark_subtraction(sciencefiles, sciencefiles, dark)\n",
    "\n",
    "# else:\n",
    "#     print('No dark frames detected. Skipping dark subtraction.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do flat division.\n",
    "\n",
    "Divide each pixel and then multiply all pixels by the average of the flat frame.\n",
    "\n",
    "If sky (sunset) flats are available, those are used. If they are not available, dome flats are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sky flats if available, use dome flats if not\n",
    "if 'sky flat' in list(set(obj_list)):\n",
    "    flattype = 'sky flat'\n",
    "else:\n",
    "    flattype = 'dome flat'\n",
    "    \n",
    "flatfilts = list(set(df_log.filt[df_log.object == flattype]))\n",
    "for flatfilt in flatfilts:\n",
    "    # find all the files with this filter\n",
    "    flatfiles = list(df_log.file[(df_log.object == flattype) & (df_log.filt == flatfilt)])\n",
    "    scienceobjects = list(set(df_log.object[(df_log.object != 'bias') &\n",
    "                                            (df_log.object != 'dark') &\n",
    "                                            (df_log.object != 'dome flat') &\n",
    "                                            (df_log.object != 'sky flat') &\n",
    "                                            (df_log.object != 'focus') &\n",
    "                                            (df_log.filt == flatfilt)]))\n",
    "    \n",
    "    # calculate the average flat frame\n",
    "    if len(flatfiles) > 1:\n",
    "        flatdata = []\n",
    "        for flatfile in flatfiles:\n",
    "            hdul = fits.open(flatfile)\n",
    "            flatdata.append(hdul[0].data)\n",
    "            hdul.close()\n",
    "        flat = np.stack(flatdata).mean(axis=0)\n",
    "    else:\n",
    "        hdul = fits.open(flatfile)\n",
    "        flat = hdul[0].data\n",
    "        hdul.close()\n",
    "        \n",
    "    if len(scienceobjects) > 0:\n",
    "        for scienceobject in scienceobjects:\n",
    "            sciencefiles = list(df_log.file[(df_log.object == scienceobject) &\n",
    "                                            (df_log.filt == flatfilt)])\n",
    "            \n",
    "            # make a new directory for each science target / filter combination\n",
    "            thisdir = scienceobject + '_' + flatfilt + '/'\n",
    "            os.makedirs(rootdir+reddir+thisdir)\n",
    "\n",
    "            # define reduced file names\n",
    "            short_sciencefiles = [file.split('/')[-1] for file in sciencefiles]\n",
    "            framenum = [frame.split('_')[0] for frame in short_sciencefiles]\n",
    "            redfiles = [rootdir + reddir + thisdir + frame + '_red.fits' for frame in framenum]\n",
    "\n",
    "            # do flat division\n",
    "            if len(sciencefiles) > 0:\n",
    "                flat_division(sciencefiles, redfiles, flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're done! Your reduced images are now ready for your viewing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
